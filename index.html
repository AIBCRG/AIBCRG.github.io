<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Neuromorphic Vision in Human-Robot Interaction</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            background: linear-gradient(135deg, #e0f7fa 0%, #b2ebf2 50%, #80deea 100%);
            min-height: 100vh;
        }

        nav {
            background: rgba(255, 255, 255, 0.95);
            padding: 15px 0;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
            position: sticky;
            top: 0;
            z-index: 1000;
        }

        .nav-container {
            max-width: 1200px;
            margin: 0 auto;
            display: flex;
            justify-content: center;
            gap: 20px;
            padding: 0 20px;
        }

        .nav-btn {
            padding: 12px 30px;
            background: linear-gradient(135deg, #0288d1, #4fc3f7);
            color: white;
            border: none;
            border-radius: 25px;
            font-size: 1.1em;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 4px 10px rgba(2, 136, 209, 0.3);
        }

        .nav-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 15px rgba(2, 136, 209, 0.4);
        }

        .nav-btn.active {
            background: linear-gradient(135deg, #01579b, #0277bd);
        }

        .section {
            display: none;
        }

        .section.active {
            display: block;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }

        header {
            background: rgba(255, 255, 255, 0.95);
            padding: 40px;
            border-radius: 15px;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);
            margin-bottom: 30px;
            text-align: center;
        }

        h1 {
            color: #0288d1;
            font-size: 2.5em;
            margin-bottom: 10px;
        }

        .subtitle {
            color: #666;
            font-size: 1.2em;
            font-weight: 300;
        }

        .intro-section {
            background: rgba(255, 255, 255, 0.95);
            padding: 40px;
            border-radius: 15px;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);
            margin-bottom: 30px;
        }

        .intro-section h2 {
            color: #0277bd;
            margin-bottom: 20px;
            font-size: 2em;
            border-bottom: 3px solid #4fc3f7;
            padding-bottom: 10px;
        }

        .intro-section p {
            margin-bottom: 15px;
            font-size: 1.1em;
            text-align: justify;
        }

        .highlight-box {
            background: linear-gradient(135deg, #b3e5fc, #e1f5fe);
            padding: 20px;
            border-radius: 10px;
            border-left: 4px solid #0288d1;
            margin: 20px 0;
        }

        .applications-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 25px;
            margin-top: 30px;
        }

        .app-card {
            background: rgba(255, 255, 255, 0.95);
            padding: 30px;
            border-radius: 15px;
            box-shadow: 0 5px 20px rgba(0, 0, 0, 0.15);
            transition: transform 0.3s ease, box-shadow 0.3s ease;
        }

        .app-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.25);
        }

        .app-card h3 {
            color: #0288d1;
            margin-bottom: 15px;
            font-size: 1.5em;
            display: flex;
            align-items: center;
        }

        .app-card h3::before {
            content: "●";
            color: #4fc3f7;
            margin-right: 10px;
            font-size: 1.2em;
        }

        .app-card p {
            color: #555;
            line-height: 1.8;
        }

        .key-features {
            background: rgba(255, 255, 255, 0.95);
            padding: 40px;
            border-radius: 15px;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);
            margin-top: 30px;
        }

        .key-features h2 {
            color: #0277bd;
            margin-bottom: 25px;
            font-size: 2em;
            text-align: center;
        }

        .features-list {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin-top: 20px;
        }

        .feature-item {
            background: linear-gradient(135deg, #e1f5fe, #b3e5fc);
            padding: 20px;
            border-radius: 10px;
            border-left: 3px solid #4fc3f7;
        }

        .feature-item h4 {
            color: #0288d1;
            margin-bottom: 10px;
        }

        .team-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
            gap: 30px;
            margin-top: 30px;
        }

        .team-member {
            background: rgba(255, 255, 255, 0.95);
            padding: 30px;
            border-radius: 15px;
            box-shadow: 0 5px 20px rgba(0, 0, 0, 0.15);
            text-align: center;
            transition: transform 0.3s ease, box-shadow 0.3s ease;
        }

        .team-member:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.25);
        }

        .member-photo {
            width: 150px;
            height: 150px;
            border-radius: 50%;
            object-fit: cover;
            margin: 0 auto 20px;
            border: 4px solid #4fc3f7;
            background: linear-gradient(135deg, #e1f5fe, #b3e5fc);
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 3em;
            color: #0288d1;
        }

        .member-name {
            color: #0277bd;
            font-size: 1.5em;
            margin-bottom: 10px;
            font-weight: 600;
        }

        .member-role {
            color: #0288d1;
            font-size: 1.1em;
            margin-bottom: 15px;
            font-weight: 500;
        }

        .member-bio {
            color: #555;
            line-height: 1.6;
            margin-bottom: 15px;
        }

        .member-links {
            display: flex;
            justify-content: center;
            gap: 15px;
            margin-top: 15px;
        }

        .member-links a {
            color: #0288d1;
            text-decoration: none;
            font-size: 0.9em;
            padding: 8px 15px;
            border: 2px solid #4fc3f7;
            border-radius: 20px;
            transition: all 0.3s ease;
        }

        .member-links a:hover {
            background: #4fc3f7;
            color: white;
        }

        footer {
            text-align: center;
            padding: 30px;
            color: white;
            margin-top: 40px;
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 2em;
            }
            
            .applications-grid {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>
    <nav>
        <div class="nav-container">
            <button class="nav-btn active" onclick="showSection('home')">Home</button>
            <button class="nav-btn" onclick="showSection('team')">Team</button>
        </div>
    </nav>

    <div id="home" class="section active">
        <div class="container">
        <header>
            <h1>Neuromorphic/Event Vision</h1>
            <p class="subtitle">Advancing Human-Robot Interaction and Collaboration</p>
        </header>

        <div class="intro-section">
            <h2>What is Neuromorphic/Event Vision?</h2>
            <p>
                Neuromorphic vision, also known as event-based vision, represents a paradigm shift in how machines perceive the visual world. Unlike traditional frame-based cameras that capture images at fixed intervals, event cameras are bio-inspired sensors that mimic the human retina by asynchronously detecting changes in brightness at each pixel independently.
            </p>
            <p>
                These revolutionary sensors generate "events" only when pixel-level brightness changes occur, resulting in a stream of asynchronous events with microsecond temporal resolution. This approach offers several compelling advantages: extremely high temporal resolution (up to 1 million events per second), high dynamic range (>120dB), low latency (<1ms), and significantly reduced data redundancy.
            </p>
            <div class="highlight-box">
                <strong>Key Innovation:</strong> Event cameras do not capture redundant information from static scenes, making them highly efficient for detecting motion and changes in dynamic environments—perfect for real-time human-robot interaction scenarios.
            </div>
        </div>

        <div class="intro-section">
            <h2>Applications in Human-Robot Interaction (HRI) and Collaboration (HRC)</h2>
            <p>
                The unique properties of neuromorphic vision make it exceptionally well-suited for human-robot interaction and collaboration tasks. The high temporal resolution and low latency enable robots to perceive and respond to human actions in real-time, while the low power consumption and robustness to lighting variations make these systems practical for deployment in diverse real-world environments.
            </p>
        </div>

        <div class="applications-grid">
            <div class="app-card">
                <h3>Gesture Recognition</h3>
                <p>
                    Event cameras excel at capturing fast hand and arm movements with precise temporal detail. This enables natural, intuitive gesture-based communication between humans and robots, allowing for touchless control interfaces and seamless command recognition even in challenging lighting conditions. The high temporal resolution captures subtle gesture nuances that traditional cameras might miss.
                </p>
            </div>

            <div class="app-card">
                <h3>Human Action Recognition</h3>
                <p>
                    Neuromorphic sensors can detect and classify complex human actions and activities in real-time by tracking motion patterns with microsecond precision. This capability is crucial for collaborative robots that need to understand what humans are doing to coordinate tasks effectively, ensure safety, and adapt their behavior to human workflows in shared workspaces.
                </p>
            </div>

            <div class="app-card">
                <h3>Facial Expression Recognition</h3>
                <p>
                    By capturing subtle facial muscle movements and micro-expressions with high temporal fidelity, event-based vision enables robots to perceive human emotional states and engagement levels. This emotional intelligence is essential for creating more empathetic and socially aware robots that can adapt their interaction style based on human affect and mental state.
                </p>
            </div>

            <div class="app-card">
                <h3>Human Trajectory Prediction</h3>
                <p>
                    The continuous, asynchronous nature of event data allows for highly accurate prediction of human movement trajectories. This is critical for collision avoidance, path planning, and proactive robot behavior in collaborative settings. Robots can anticipate where humans will move next and adjust their actions accordingly to maintain safe and efficient collaboration.
                </p>
            </div>

            <div class="app-card">
                <h3>Human Detection and Tracking</h3>
                <p>
                    Event cameras provide robust human detection and tracking capabilities even in fast motion scenarios, occlusions, and extreme lighting conditions. The high dynamic range and motion sensitivity ensure that humans are reliably detected, which is fundamental for safety-critical applications and maintaining awareness of all humans in the collaborative workspace.
                </p>
            </div>
        </div>

        <div class="key-features">
            <h2>Why Neuromorphic Vision for HRI/HRC?</h2>
            <div class="features-list">
                <div class="feature-item">
                    <h4>⚡ Ultra-Low Latency</h4>
                    <p>Microsecond-level response time enables real-time interaction and immediate robot reaction to human actions.</p>
                </div>
                <div class="feature-item">
                    <h4>🔋 Energy Efficiency</h4>
                    <p>Sparse event representation significantly reduces power consumption, enabling longer operation and mobile deployment.</p>
                </div>
                <div class="feature-item">
                    <h4>🌓 High Dynamic Range</h4>
                    <p>Operates effectively in both bright sunlight and low-light conditions without adjustment or saturation.</p>
                </div>
                <div class="feature-item">
                    <h4>🎯 Motion Sensitivity</h4>
                    <p>Exceptional at detecting fast movements and subtle motions that are critical for human action understanding.</p>
                </div>
                <div class="feature-item">
                    <h4>📊 Data Efficiency</h4>
                    <p>Only captures relevant changes, reducing data processing requirements and bandwidth needs.</p>
                </div>
                <div class="feature-item">
                    <h4>🛡️ Privacy Preserving</h4>
                    <p>Event-based representation inherently anonymizes static visual information while capturing motion dynamics.</p>
                </div>
            </div>
        </div>

        <footer>
            <p>&copy; 2025 Neuromorphic Vision Research | Advancing the Future of Human-Robot Interaction</p>
        </footer>
    </div>
    </div>

    <div id="team" class="section">
        <div class="container">
            <header>
                <h1>Our Team</h1>
                <p class="subtitle">Meet the Researchers Behind Neuromorphic Vision</p>
            </header>

            <div class="intro-section">
                <h2>Research Team</h2>
                <p>
                    Our interdisciplinary team brings together expertise in computer vision, robotics, neuromorphic engineering, and human-robot interaction to advance the state-of-the-art in event-based vision systems.
                </p>
            </div>

            <div class="team-grid">
                <div class="team-member">
                    <div class="member-photo">👤</div>
                    <h3 class="member-name">Dr. Filippo Sanfilippo</h3>
                    <p class="member-role">Professor</p>
                    <p class="member-bio">
                        Leading research in neuromorphic vision systems with 10+ years of experience in event-based sensing and human-robot interaction.
                    </p>
                    <div class="member-links">
                        <a href="#" target="_blank">filippo.sanfilippo@uia.no</a>
                        <a href="#" target="_blank">LinkedIn</a>
                        <a href="#" target="_blank">Scholar</a>
                    </div>
                </div>

                <div class="team-member">
                    <div class="member-photo">👤</div>
                    <h3 class="member-name">Muhammad Hamza Zafar</h3>
                    <p class="member-role">PhD Researcher</p>
                    <p class="member-bio">
                        Specializes in gesture recognition and real-time event processing algorithms for collaborative robotics applications.
                    </p>
                    <div class="member-links">
                        <a href="#" target="_blank">muhammad.h.zafar@uia.no</a>
                        <a href="#" target="_blank">LinkedIn</a>
                        <a href="#" target="_blank">Scholar</a>
                    </div>
                </div>

                <div class="team-member">
                    <div class="member-photo">👤</div>
                    <h3 class="member-name">Syed Kumayl Raza Moosavi</h3>
                    <p class="member-role">PhD Researcher</p>
                    <p class="member-bio">
                        Working on human action recognition and trajectory prediction using event cameras for safe human-robot collaboration.
                    </p>
                    <div class="member-links">
                        <a href="#" target="_blank">syed.k.moosavi@uia.no</a>
                        <a href="#" target="_blank">LinkedIn</a>
                        <a href="#" target="_blank">Scholar</a>
                    </div>
                </div>

                <div class="team-member">
                    <div class="member-photo">👤</div>
                    <h3 class="member-name">Alex Chen</h3>
                    <p class="member-role">PhD Candidate</p>
                    <p class="member-bio">
                        Focuses on facial expression recognition and emotion detection using neuromorphic sensors for empathetic robots.
                    </p>
                    <div class="member-links">
                        <a href="#" target="_blank">Email</a>
                        <a href="#" target="_blank">LinkedIn</a>
                        <a href="#" target="_blank">Scholar</a>
                    </div>
                </div>

                <div class="team-member">
                    <div class="member-photo">👤</div>
                    <h3 class="member-name">Sarah Johnson</h3>
                    <p class="member-role">Research Engineer</p>
                    <p class="member-bio">
                        Develops hardware-software integration for event-based vision systems in real-time robotic platforms.
                    </p>
                    <div class="member-links">
                        <a href="#" target="_blank">Email</a>
                        <a href="#" target="_blank">LinkedIn</a>
                        <a href="#" target="_blank">Scholar</a>
                    </div>
                </div>

                <div class="team-member">
                    <div class="member-photo">👤</div>
                    <h3 class="member-name">Michael Brown</h3>
                    <p class="member-role">Master's Student</p>
                    <p class="member-bio">
                        Researching human detection and tracking algorithms for dynamic environments using event cameras.
                    </p>
                    <div class="member-links">
                        <a href="#" target="_blank">Email</a>
                        <a href="#" target="_blank">LinkedIn</a>
                        <a href="#" target="_blank">Scholar</a>
                    </div>
                </div>
            </div>

            <footer>
                <p>&copy; 2025 Neuromorphic Vision Research | Advancing the Future of Human-Robot Interaction</p>
            </footer>
        </div>
    </div>

    <script>
        function showSection(sectionId) {
            // Hide all sections
            document.querySelectorAll('.section').forEach(section => {
                section.classList.remove('active');
            });
            
            // Remove active class from all buttons
            document.querySelectorAll('.nav-btn').forEach(btn => {
                btn.classList.remove('active');
            });
            
            // Show selected section
            document.getElementById(sectionId).classList.add('active');
            
            // Add active class to clicked button
            event.target.classList.add('active');
            
            // Scroll to top
            window.scrollTo({ top: 0, behavior: 'smooth' });
        }
    </script>
</body>
</html>




